import os
import random
import requests
import re
from dotenv import load_dotenv
from django.core.management.base import BaseCommand
from books.models import Book, Author, Category

load_dotenv()

class Command(BaseCommand):
    help = 'ë„ì„œ ìˆ˜ì§‘ ë° ì‘ê°€ ì •ë³´ë¥¼ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì •ì œëœ ì´ë¦„ ê¸°ì¤€)'

    def handle(self, *args, **options):
        ttb_key = os.getenv("ALADIN_TTBKEY")
        if not ttb_key:
            print("âŒ ALADIN_TTBKEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        else:
            print(f"âœ… ALADIN_TTBKEY ë¡œë“œ ì„±ê³µ: {ttb_key[:5]}******")

        keywords = ['ì‚¬ë‘', 'ìš°ì •', 'ì„±ì¥', 'ì² í•™', 'ê°ë™', 'ì¶”ë¦¬', 'ìê¸°ê³„ë°œ', 'ì¸ë¬¸', 'ì—ì„¸ì´', 'ì—¬í–‰']
        random.shuffle(keywords)

        collected_isbns = set()
        total_saved = 0

        for keyword in keywords:
            if total_saved >= 300:
                break

            print(f"\nğŸ” í‚¤ì›Œë“œ '{keyword}'ì—ì„œ ì±… ìˆ˜ì§‘ ì¤‘...")

            search_url = "https://www.aladin.co.kr/ttb/api/ItemSearch.aspx"
            search_params = {
                "ttbkey": ttb_key,
                "Query": keyword,
                "QueryType": "Keyword",
                "MaxResults": 100,
                "start": 1,
                "SearchTarget": "Book",
                "output": "js",
                "Version": "20131101",
                "Cover": "Big"
            }

            try:
                response = requests.get(search_url, params=search_params)
                print(f"[ì‘ë‹µ ìƒíƒœ ì½”ë“œ] {response.status_code}")

                if response.status_code != 200:
                    print(f"âš ï¸ API ì˜¤ë¥˜ ì‘ë‹µ:\n{response.text[:300]}...")
                    continue

                data = response.json().get('item', [])
                print(f"ğŸ“š '{keyword}' í‚¤ì›Œë“œë¡œ {len(data)}ê¶Œ ìˆ˜ì‹ ")

            except requests.RequestException as e:
                print(f"ğŸ”´ ìš”ì²­ ì˜ˆì™¸ ë°œìƒ: {e}")
                continue

            for item in data:
                if total_saved >= 300:
                    break

                isbn13 = item.get('isbn13')
                if not isbn13:
                    print("âŒ ISBN13 ì—†ìŒ â†’ ê±´ë„ˆëœ€")
                    continue
                if isbn13 in collected_isbns:
                    print("ğŸ” ì¤‘ë³µ ISBN13 â†’ ê±´ë„ˆëœ€")
                    continue

                title = item.get('title', '').strip()
                raw_author_name = item.get('author', '').strip()
                category_name = item.get('categoryName', '').strip()

                if not title or not raw_author_name:
                    print("âŒ ì œëª© ë˜ëŠ” ì €ì ì—†ìŒ â†’ ê±´ë„ˆëœ€")
                    continue

                print(f"âœ… ì €ì¥ ëŒ€ìƒ: {title[:30]} / {raw_author_name} / ì¶œíŒì‚¬: {item.get('publisher')}")

                author, _ = Author.objects.get_or_create(name=raw_author_name)

                parsed_author_name = self.extract_primary_author_name(raw_author_name)
                wiki_data = self.get_wikipedia_data(parsed_author_name)

                author.profile_image = wiki_data.get('thumbnail', {}).get('source') if wiki_data else None
                author.biography = wiki_data.get('extract') if wiki_data else ''
                author.save()

                category, _ = Category.objects.get_or_create(name=category_name)

                Book.objects.update_or_create(
                    isbn13=isbn13,
                    defaults={
                        "title": title,
                        "author": author,
                        "category": category,
                        "description": item.get('description', ''),
                        "cover_image_url": item.get('cover', ''),
                        "pub_date": item.get('pubDate', ''),
                        "publisher": item.get('publisher', ''),
                        "link": item.get('link', ''),
                    }
                )

                collected_isbns.add(isbn13)
                total_saved += 1

        print(f"\nğŸ“¦ ì´ ì €ì¥ ì™„ë£Œ: {total_saved}ê¶Œ")

    def extract_primary_author_name(self, raw_author_str):
        parts = [part.strip() for part in raw_author_str.split(',')]
        first = parts[0]
        return re.sub(r'\([^)]*\)', '', first).strip()

    def get_wikipedia_data(self, author_name):
        try:
            url = f"https://ko.wikipedia.org/api/rest_v1/page/summary/{author_name}"
            response = requests.get(url)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"ğŸ”» ìœ„í‚¤í”¼ë””ì•„ ìš”ì²­ ì‹¤íŒ¨: {author_name} / {e}")
        return None
